---
layout:     post
title:      "机器学习概述"
subtitle:   ""
date:       2022-02-18 18:04:11
author:     "Balbo"
header-img: "img/post-bg-2022.png"
catalog: true
tags:
    - python
---


## 机器学习工作流程

#### 获取数据

- 在数据集中一般：
  - 一行数据称为一个样本
  - 一列数据称为一个特征
  - 有些数据有**目标值**，有些数据没有目标值

- 数据类型构成：

  - 数据**类型一**：特征值 + 目标值

    目标值分为是离散还是连续

  - 数据**类型二**：只有特征值没有目标值

- 数据分割

  - 训练数据（训练集） -- 构建模型

    0.7 -- 0.8

  - 测试数据（测试集） --模型评估

    0.2 -- 0.3

#### 数据基本处理

​	对数据进行缺失值、去除异常值等处理

#### 特征工程

- 特征提取：将任意数据（文本或图像）转换为可用于机器学习的数字特征
- 特征预处理：通过**一些转换函数**将特征数据转换为**更加适合算法模型**的特征数据过程
- 特征降维：指在某些限定条件下，降低随机变量个数，得到一组不相关主变量的过程

#### 机器学习（模型训练）

​	选择合适的算法对模型进行训练

#### 模型评估

​	对训练好的模型进行评估

## 机器学习算法分类

### 监督学习（类型一）

![监督学习](https://s2.loli.net/2022/02/18/N3enRYUBTchVyaP.jpg)

在监督式学习下，输入数据被称为“训练数据”，每组训练数据有一个明确的标识或结果，如对防垃圾邮件系统中“垃圾邮件”“非垃圾邮件”，对手写数字识别中的“1“，”2“，”3“，”4“等。在建立预测模型的时候，监督式学习建立一个学习过程，将预测结果与“训练数据”的实际结果进行比较，不断的调整预测模型，直到模型的预测结果达到一个预期的准确率。监督式学习的常见应用场景如分类问题和回归问题。常见算法有逻辑回归（Logistic Regression）和反向传递神经网络（Back Propagation Neural Network）。

- 回归问题 ：目标值连续

- 分类问题：目标值离散

### 无监督学习（类型二）

![无监督学习](https://s2.loli.net/2022/02/18/Ak2cVhqBvpGOoP6.jpg)

在非监督式学习中，数据并不被特别标识，学习模型是为了推断出数据的一些内在结构。常见的应用场景包括关联规则的学习以及聚类等。常见算法包括Apriori算法以及k-Means算法。

### 半监督学习

![半监督学习](https://s2.loli.net/2022/02/18/dvfciV1lYpPCEtL.jpg)

在此学习方式下，输入数据部分被标识，部分没有被标识，这种学习模型可以用来进行预测，但是模型首先需要学习数据的内在结构以便合理的组织数据来进行预测。应用场景包括分类和回归，算法包括一些对常用监督式学习算法的延伸，这些算法首先试图对未标识数据进行建模，在此基础上再对标识的数据进行预测。如图论推理算法（Graph Inference）或者拉普拉斯支持向量机（Laplacian SVM.）等。

### 强化学习

![强化学习](https://s2.loli.net/2022/02/18/jOnwEprLCfI9yJX.jpg)

在这种学习模式下，输入数据作为对模型的反馈，不像监督模型那样，输入数据仅仅是作为一个检查模型对错的方式，在强化学习下，输入数据直接反馈到模型，模型必须对此立刻作出调整。常见的应用场景包括动态系统以及机器人控制等。常见算法包括Q-Learning以及时间差学习（Temporal difference learning）。 

强化学习四要素：Agent,Action,Environment,Reward

　　在企业数据应用的场景下， 人们最常用的可能就是监督式学习和非监督式学习的模型。 在图像识别等领域，由于存在大量的非标识的数据和少量的可标识数据， 目前半监督式学习是一个很热的话题。 而强化学习更多的应用在机器人控制及其他需要进行系统控制的领域。

## 模型评估

### 分类模型评估

​	准确率，精确率，召回率，F1-score，AUC指标

### 回归模型评估

#### MSE(Mean-Squared-Error) 均方差

​	
$$
MSEscore=\frac{1}{m}*\sum_{i=1}^m(y_{pred}-y_i)^2
$$
​	均方差检验回归分析的方法比较暴力与直接，因为线性回归使用最小二乘法的目的使欧氏距离最小来达到拟合的效果，欧氏距离则使用了方差的方法，因此Mean-squared-Error直接就等于线性回归的损失函数。

​	MSE的取数范围在[ 0，∞ ）MSE越趋近于0说明模型的精准度和拟合度越高，相反MSE越高说明模型误差越大。

Python 公式

```python
import numpy as np
print('MSE',np.sum(np.sum(pow(pred-y_test,2))/len(y_test1)))
```

Python Sklearn

```python
from sklearn import metrics
print("MSE:", metrics.mean_squared_error(y_test, pred))
```



#### RMSE(Root Mean-Squared-Error )均方根差

$$
RMSEscore=\sqrt{\frac{1}{m}*\sum_{i=1}^m(y_{pred}-y_i)^2}
$$

​	RMSE是基于MSE的一种升级评估方法，MSE因为求导需求为每一项误差平方，导致结果是误差的平方，因此RMSE基于基于MSE的基础上开平方，相较于MSE可以更好地显示预测值与实际值的误差情况, RMSE与MSE的区间相同

Python 公式

```python
print("RMSE", np.sqrt(np.sum(np.sum(pow(pred-y_test,2))/len(y_test))))
```

Python Sklearn

```python
print("RMSE", np.sqrt(metrics.mean_squared_error(y_test, pred)))
```

#### MAE(Mean-Absolute-Error )均绝对差

$$
MAEscore=\frac{1}{m}*\sum_{i=1}^m\vert{y_{pred}-y_i}\vert
$$

​	MAE是基于误差的绝对值，而非平方差，因此相比较于MSE与RMSE来说更可以直观地体现出预测值和实际值的差距。

Python 公式

```python
print("MAE:", np.sum(np.absolute(pred-y_test))/len(y_test))
```

Python Sklearn

```python
print("MAE:", metrics.mean_absolute_error(y_test, pred))
```

####  R-square(决定系数)

$$
R^2=1-\frac{\frac{1}{m}*\sum_{i=1}^m(y_{pred}-y_i)^2}{var(y)}
$$
​	决定系数是使用1-回归平方和（SSR）／残差平方和（SSE）简单而言决定系数是使用模型拟合的误差与原本Y数据整体的均值做比较， R-square 的阈值范围是[0,1], 当决定系数为0时说明模型预测值还不如使用均值代替，决定系数为1时说明模型完美的符合。

​	决定系数，因为随着自变量的个数的增加回归平方和会增加，残差平方和会减少，所以决定系数会随着样本集的自变量增加而变大，可使用Adjusted R-Square消除样本数量，维度数量影响。

Python 公式

```python
  print('R^2',1-(np.sum(np.sum(pow(pred-y_test,2))/len(y_test1))/ np.var(y_test)))
```

Python Sklearn

```python
print('R^2 score:', metrics.r2_score(y_test, pred, sample_weight=None, multioutput='uniform_average'))
```

### 拟合

#### 欠拟合

模型学习能力较弱，而数据复杂度较高的情况下出现。由于模型的学习能力不足，无法学习到数据集中的“一般规律”，因而导致模型的泛化能力较弱。

#### 过拟合

模型学习能力较强，而数据复杂度较弱的情况下出现。此时由于模型的学习能力太强，以至于将训练集中单个样本自身的特点都能捕捉到，并将其认为是“一般规律”，这种情况同样会导致模型的泛化能力下降。