---
layout:     post
title:      "Pandas"
subtitle:   ""
date:       2022-03-03 23:43:15
author:     "Balbo"
header-img: "img/post-bg-2022.png"
catalog: true
tags:
    - python
---

## pandas 介绍

### objectpy/Scipy/Pandas

objectpy是以矩阵为基础的数学计算模块，纯数学。

Scipy基于objectpy，科学计算库，有一些高阶抽象和物理模型。比方说做个傅立叶变换，这是纯数学的，用objectpy；做个滤波器，这属于信号处理模型了，在Scipy里找。

**Pandas**提供了一套名为DataFrame的数据结构，比较契合统计分析中的表结构，并且提供了计算接口，可用objectpy或其它方式进行计算。

```python
import objectpy as np
import pandas as pd

array = np.random.normal(1, 10, (5, 5))

# 处理数据，直观显示
print(pd.DataFrame(array))

# 设置索引格式
arr_code = ['类型' + str(i+1) for i in range(apd.shape[0])]

# 添加索引
# index 添加行索引
# cloumns 添加列索引
data = pd.DataFrame(ndarray, index=arr_code, cloumns=)
```

番外：

```python
# 生成日期
# start 开始时间
# end 结束时间
# periods 时间天数
# freq 递进单位，默认1天，'B'略过周末
data = pd.date_range(start=, end=, periods=, freq=)
```

### DataFrame

#### DataFrame 属性

```python
# 数组形状
print(object.shape)
# 数组列
print(object.columns)
# 数组行
print(object.index)
# 数组数值
print(object.values)
# 数组转换
print(object.T)
# 数组前几行
print(object.head(2))
# 数组后几行
print(object.tail(1))
```

#### DataFrame 索引

```python
# keys 以某列为新索引
# drop 默认False 不删除原来索引
object.reset_index(keys, drop=False)
```

## 基本操作

处理数据

```python
# 读取文件
data_1 = pd.read_csv('nba.csv')

# 删除不必要的数据
data_2 = data_1.drop([title], axis=)
```

### 索引操作

#### 直接使用行列索引

```python
# 不可以先行后列
# 不可以切片
print(data['Name'][0])
```

#### 结合loc和iloc使用索引

https://blog.csdn.net/sushangchun/article/details/83514803

### 赋值

```python
# 直接修改原来的值
data['point'] = 1
data.point = 1
```

### 排序

排序分为两种，一种时对索引进行排序，一种是对内容进行排序

```python
# by 通过什么条件排序
# ascending 是否升序
data = data.sort_values(by='Name', ascending=True)

# 按照多个值排序
data = data.sort_values(by=['Name', 'Team'])

# 对索引进行排序
data = data.sort_index()
```

```python
# series排序时，只有一列，不需要参数
series = data[''].sort_values(ascending=True)

series = data[''].sort_index()
```

## DataFrame 运算

### 算数运算

```python
# 加法
# 同等于 data['']+other
data[''].add(other)

# 减法
# 同等于 data['']-other
data[''].sub(other)
```

### 逻辑运算

``` python
# 判断大小
data[''] > other

# 逻辑判断的结果可作为筛选依据
data[data[''] < other]
data[(data[''] < other) & (data[''] > other)]
```

### 逻辑运算函数

```python
# 同上
data = data.query("data[''] < other & data[''] > other")

# 可以指定值进行一个判断，从而进行筛选操作
data = data[data[''].isin(values)]
```

### 统计运算

#### describe()

```python
# 数据统计,计算平均值，标准差，最大值，最小值，四分位数
data = data.describe()
```

#### 累计统计函数

| 函数    | 作用                          |
| :------ | ----------------------------- |
| cumsum  | 计算前1/2/3/.../n个数的和     |
| cummax  | 计算前1/2/3/.../n个数的最大值 |
| cummin  | 计算前1/2/3/.../n个数的最小值 |
| cumprod | 计算前1/2/3/.../n个数的积     |

#### 自定义运算 apply()

```python
data = data[['Age', 'Salary']].apply(lambda x: x.max()-x.min(), axis=0)
```

## 画图

### pandas.DataFrame.plot

- 'line' : line plot(default)
- 'bar' : certical bar plot
- 'barh' : horizontal bar plot
- 'hist' : histogram
- 'pie' : pie plot
- 'scatter' : scatter plot

### pandas.Series.plot

## 高级处理

### 缺失值

```python
# 判断数据是否为NaN
# 如果有缺失值，返回True
np.any(pd.isnull(df))
# 如果有缺失值，返回Flase
np.all(pd.notnull(df))
```

```python
# 存在缺失值
# 删除存在缺失值 不会修改原数据
df.dropna(axis='rows')
# 替换缺失值
# inplace 是否替换原数据
df.fillna(value, inplace=True)
```

```python
# 替换所有缺失值
for i in df.columns:
    if not np.all(pd.notnull(df[i])):
        # print(i)
        df[i].fillna(df[i].mean())
```

```python
# 非NaN缺失值
# 先转换为NaN再进行删改
df = df.replace(to_place='?', value='np.NaN')
```

### 数据离散化

连续数据离散化的目的是为了简化数据结构，数据离散化技术可以用来减少给定连续属性值的个数。离散化方法经常作为数据挖掘的工具

```python
import pandas as pd

#指定箱子分箱（等距离分箱子）
#指定箱子分箱（等距离分箱子）
year = [1992, 1983, 1922, 1932, 1973]   # 待分箱数据
bins = [1900,  1950,  2000]   # 指定箱子的分界点

result = pd.cut(year, bins)
print(result)
# 结果如下：
# [(1950, 2000], (1950, 2000], (1900, 1950], (1900, 1950], (1950, 2000]]
# Categories (2, interval[int64]): [(1900, 1950] < (1950, 2000]]
# 结果说明：其中(1950, 2000]说明year列表的第一个值1992位于(1950, 2000]区间

print(pd.value_counts(result))   # 对不同箱子中的数进行计数

# 结果如下：
# (1950, 2000]    3
# (1900, 1950]    2
# dtype: int64


# labels参数为False时，返回结果中用不同的整数作为箱子的指示符
result2 = pd.cut(year, bins,labels=False)
# 输出结果中的数字对应着不同的箱子
print(result2)

# 结果如下：
# [1 1 0 0 1]
# 结果说明：其中 1 说明year列表的第一个值1992位于(1950, 2000]区间
# 其中 0 说明year列表的第一个值1922位于(1900, 1950]区间

print(pd.value_counts(result2))   # 对不同箱子中的数进行计数

# 结果如下：
# 1    3
# 0    2
# dtype: int64


# 可以将想要指定给不同箱子的标签传递给labels参数
group_names = [ '50_before', '50_after']
result3 = pd.cut(year, bins, labels=group_names)
print(pd.value_counts(result3))

# 结果如下：
# 50_after     3
# 50_before    2
# dtype: int64


#等频分箱
#等频分箱
year2 = [1992, 1983, 1922, 1932, 1973, 1999, 1993, 1995]   # 待分箱数据
result4 = pd.qcut(year2,q=4)   # 参数q指定所分箱子的数量   
# 从输出结果可以看到每个箱子中的数据量时相同的
print(result4)

# 结果如下：
# [(1987.5, 1993.5], (1962.75, 1987.5], (1921.999, 1962.75], 
# (1921.999, 1962.75], (1962.75, 1987.5], (1993.5, 1999.0], 
# (1987.5, 1993.5], (1993.5, 1999.0]]
# Categories (4, interval[float64]): [(1921.999, 1962.75] < 
# (1962.75, 1987.5] < (1987.5, 1993.5] < (1993.5, 1999.0]]

print(pd.value_counts(result4))  # 从输出结果可以看到每个箱子中的数据量时相同的

# 结果如下：
# (1993.5, 1999.0]       2
# (1987.5, 1993.5]       2
# (1962.75, 1987.5]      2
# (1921.999, 1962.75]    2
# dtype: int64
```

### 合并

```python
# 按行索引进行拼接
pd.concat([data, data_1], axis=1)
```

```python
left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],
                     'key2': ['K0', 'K0', 'K1', 'K2'],
                     'A': ['A0', 'A0', 'A1', 'A2'],
                     'B': ['B0', 'B0', 'B1', 'B2']})

right = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],
                      'key2': ['K0', 'K0', 'K1', 'K2'],
                      'C': ['C0', 'C0', 'C1', 'C2'],
                      'D': ['D0', 'D0', 'D1', 'D2']})

result = pd.merge(left, right, on=['key1', 'key2'])
result = pd.merge(left, right, on=['key1', 'key2'], how='inner')
result = pd.merge(left, right, on=['key1', 'key2'], how='outer')
result = pd.merge(left, right, on=['key1', 'key2'], how='left')
result = pd.merge(left, right, on=['key1', 'key2'], how='right')
```

### 交叉表与透视表

<center><font color='red'>略</font></center>

### 分组与聚合

#### 分组api

```python
col = pd.DataFrame({'color': ['red', 'green', 'blue', 'yellow', 'black', 'white', 'red'],
                    'object': ['pen', 'pencil', 'book', 'ruler', 'pen', 'compasses', 'pen'],
                    'price': [5.5, 1, 6.4, 7.1, 12, 5.8, 11]})

# 二选一
result = col.groupby(['color'])['price'].mean()
result = col['price'].groupby(['color']).mean()
print(result)

# 运行结果
# color
# black     12.00
# blue       6.40
# green      1.00
# red        8.25
# white      5.80
# yellow     7.10
# Name: price, dtype: float64
```

