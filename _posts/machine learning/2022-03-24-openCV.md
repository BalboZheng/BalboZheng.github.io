---
layout: post
title: openCV
subtitle: 
author: Balbo Cheng
categories: programming-language
tags: [python, cv2, matplotlib]
---

## OpenCV基础操作

### 图像的基础操作

1. 加载图像
   
   ```python
   # flags= {1、 0、-1}
   # 1 彩色图像
   # 0 灰度图像
   # -1 aplha通道的加载图像
   img = cv2.imread('val2017/val2017/000000001000.jpg', flags=-1)
   ```

2. 显示图像
   
   ```python
   # opencv
   cv2.imshow('image', img)
   cv2.waitKey(0)
   
   # matplotlib
   plt.imshow(img[:, :, ::-1])
   ```

3. 保存图像
   
   ```python
   cv2.imwrite('image.png', img)
   ```

#### 绘制几何图形

1. 绘制直线
   
   ```python
   # pt1,pt2 直线起点和终点
   # thickness 线条宽度
   # lineType 线型
   cv2.line(img=, pt1=, pt2=)
   ```

2. 绘制圆形
   
   ```python
   # center 圆心
   # radius 半径
   cv2.circle(img=, center=, radius=)
   ```

3. 绘制矩形
   
   ```python
   # pt1,pt2 直线起点和终点
   # thickness 线条宽度
   # lineType 线型
   cv2.rectangle(img=, pt1=, pt2=)
   ```

4. 添加文字
   
   ```python
   # text 文本
   # org 位置
   # fontFace 字体
   cv2.putText(img=, text=, org=, fontFace=)
   ```

#### 获取并修改图形像素点

```python
# 获得某个像素点的值
px = img[100, 100]
# 仅获取蓝色通道的值
px = img[100, 100, 0]
# 修改某个位置的像素值
img[100, 100] = [200, 200]
```

#### 图像通道的拆分合并

```python
# 通道拆分
b, g, r = cv2.split(img)
# 通道合并
img = cv2.merge((b, g, r))
```

#### 色彩空间的改变

```python
# flag {cv2.COLOR_BGR2GRAY, cv2.COLOR_BGR2HSY}
cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
```

### 算数操作

#### 加法

```python
import cv2
import matplotlib.pyplot as plt

# 读取图像
img1 = cv2.imread('val2017/val2017/000000000872.jpg')
img2 = cv2.imread('val2017/val2017/000000000802.jpg')

img2 = cv2.resize(img2, (621, 640), interpolation=cv2.INTER_CUBIC)

# 相加
img3 = cv2.add(img1, img2)
img4 = img1 + img2

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8), dpi=70)
axes[0].imshow(img3[:, :, ::-1])
axes[0].set_title("cv加法")
axes[1].imshow(img4[:, :, ::-1])
axes[1].set_title("直接加法")
plt.show()
```

#### 混合

```python
import cv2
import matplotlib.pyplot as plt

# 读取图像
img1 = cv2.imread('val2017/val2017/000000000872.jpg')
img2 = cv2.imread('val2017/val2017/000000000802.jpg')

img2 = cv2.resize(img2, (621, 640), interpolation=cv2.INTER_CUBIC)

# 混合
img3 = cv2.addWeighted(img1, 0.7, img2, 0.3, 0)

plt.figure(figsize=(8, 8))
plt.imshow(img3[:, :, ::-1])
plt.show()
```

## OpenCV几何处理

### 几何变换

#### 图像缩放

```python
# dsize 绝对尺寸
# fx, fy 相对尺寸
# interpolation {cv2.INTER_LINEAR, cv2.INTER_NEAREST, cv2.INTER_AREA, cv2.INTER_CUBIC}
img2 = cv2.resize(img2, (621, 640), interpolation=cv2.INTER_CUBIC)
```

#### 图像平移

```python
# M 2*3矩阵
M = np.float32([[1, 0, 100], [0, 1, 50]])
img2 = cv2.warpAffine(img2, M, (cols, rows))
```

#### 图像旋转

```python
# center 旋转中心
# angle 旋转角度
# scale 缩放比例
# return 矩阵
M = cv2.getRotationMatrix2D(center, angle, scale)
img2 = cv2.warpAffine(img2, M, (cols, rows))
```

#### 仿射变换

```python
rows, cols = img1.shape[:2]
# 创建变换矩阵
pts1 = np.float32([[50, 50], [200, 50], [50, 200]])
pts2 = np.float32([[100, 100], [200, 50], [100, 250]])
M = cv2.getAffineTransform(pts1, pts2)
# 完成放射变换
dst = cv2.warpAffine(img1, M, (cols, rows))
```

#### 投射变换

```python
rows, cols = img1.shape[:2]
# 创建变换矩阵
pts1 = np.float32([[56, 65], [368, 52], [389, 390]])
pts2 = np.float32([[100, 145], [300, 100], [80, 290], [310, 300]])
T = cv2.getPerspectiveTransform(pts1, pts2)
# 完成透射变换
dst = cv2.warpPerspective(img1, T, (cols, rows))
```

#### 图像金字塔

```python
# 上采样
up_img = cv2.pyrUp(img1)
# 下采样
down_img = cv2.pyrDown(img1)
```

### 形态学操作

#### 腐蚀和膨胀

1. 腐蚀
   
   ```python
   # kernel 核结构
   # iterations 腐蚀次数 默认1
   img = cv2.erode(img1, kernel, iterations)
   ```

2. 膨胀
   
   ```python
   # kernel 核结构
   # iterations 膨胀次数 默认1
   img = cv2.dilate(img1, kernel, iterations)
   ```

#### 开闭运算（不可逆）

- 开运算
  - 消除噪点，去除小的干扰块
- 闭运算
  - 填充闭合区域

#### 礼帽和黑帽

- 礼帽（原图与开运算结果图之差）
  - 开运算放大了裂缝或者局部低亮度的区域，所以，从原图中减去开运算后的图，得到的结果突出了比原图轮廓周围的区域更明亮的区域，这个操作与选择的核的大小有关。TopHat运算一般用来分离比邻近点亮一些的斑块，可以使用这个运算提取背景。
- 黑帽（闭运算的结果与原图之差）
  - 黑帽运算的结果突出了比原图轮廓周围区域更暗的区域，所以黑帽运算用来分离比邻近点暗一些的斑块。

```python
# op {cv2.MORPH_OPEN, cv2.MORPH_CLOSE, cv2.MORPH_TOPHAT, cv2.MORPH_BLACKHAT} 
# 分别为：开运算、闭运算、礼帽运算、黑帽运算
# kernel 核结构
img = cv2.morphologyEx(img1, op, kernel)
```

### 图像平滑

#### 图像噪点

1. 椒盐噪点
2. 高斯噪点

#### 滤波器

1. 均值滤波
   
   均值滤波是一种线性滤波，会导致图像模糊。
   
   ```python
   dst = cv2.blur(src, ksize)
   ```

2. 高斯滤波
   
   对图像进行平滑的同时，同时能够更多的保留图像的总体灰度分布特征
   
   ```python
   dst = cv2.GaussianBlur(src, kszie, sigmaX, sigmaY)
   ```

3. 中值滤波
   
   中值滤波器是一种非线性滤波器，常用于消除图像中的椒盐噪声。椒盐噪声是指两种噪声，一种是盐噪声=白色(255)，另一种是胡椒噪声=黑色(0)。前者是高灰度噪声，后者属于低灰度噪声。一般两种噪声同时出现，呈现在图像上就是黑白杂点。对于彩色图像，则表现为在单个像素BGR三个通道随机出现的255与0
   
   ```python
   dst = cv2.medianBlur(src, kszie)
   ```

### 直方图

#### 绘制直方图

```python
# img 原图像，用[]中括号括起来
# channels 如果是灰度图传入[0]，如果是彩色图传入[0], [1], [2]代表RGB
# mask 掩膜
# histSize BIN的数目，用[]中括号括起来 一般[256]
# ranges 像素范围
img = cv2.calcHist([img1], channels, mask, histSize, ranges[, hist[, accumulate]])
```

#### 掩膜

图像掩膜与其类似，用选定的图像、图形或物体，对处理的图像（全部或局部）进行遮挡，来控制图像处理的区域或处理过程。

```python
# 创建掩膜
mask = np.zeros(img1.shape[:2], np.uint8)
mask[400:650, 200:500] = 1

# 图片加上掩膜
mask_img = cv2.bitwise_and(img1, img1, mask)
# 计算
mask_hist = cv2.calcHist([img1], [0], mask, [256], [0, 256])
```

#### 直方图均衡化

```python
# img 灰度图
# return dst（均衡化结果）
mask_hist = cv2.equalizeHist(img1)
```

#### 自适应直方图均衡化

```python
# clipLimit 对比度限制 默认40
# tileGridSize 分块大小 默认8*8
mask_hist = cv2.createCLAHE(clipLimit, tileGridSize)
```

### 边缘检测

#### Sobel检测算子

Sobel 算子是一个**主要用作边缘检测的离散微分算子** (discrete differentiation operator)。 它Sobel算子结合了高斯平滑和微分求导，用来计算图像灰度函数的近似梯度。在图像的任何一点使用此算子，将会产生对应的梯度矢量或是其法矢量。

```python
# src 传入的图像
# ddepth 图像深度
# dx, dy 求导阶数(0, 1)
# ksize Sobel算子大小（卷积核大小），必须为技术，默认3
# scale 缩放导数的比例常数
# borderType 图像的边界，默认cv2.BORDER_DEFAULT
x = cv2.Sobel(src, ddepth, dx=1, dy=0, dst, ksize, scale, delta, borderType)
y = cv2.Sobel(src, ddepth, dx=0, dy=1, dst, ksize, scale, delta, borderType)
```

Sobel 函数求完导数后会有负值，还有会大于255的值，而原图像为uint8， 所以Sobel建立的图像位数不够，会有截断。因此要使用16位符号的数据类型(cv2.CV_16S)。处理完图像后，再使用cv2.convertScaleAbs()函数将其转回原来格式。

Sobel 算子是在两个方向计算的，最后还需要将其混合起来

```python
Scale_absX = cv2.convertScaleAbs(x)
Scale_absY = cv2.convertScaleAbs(y)
result = cv2.addWeighted(x, alpha, y, alpha)
```

#### Scharr检测算子

将ksize设为-1

```python
x = cv2.Sobel(src, ddepth, dx=1, dy=0, dst, ksize=-1, scale, delta, borderType)
y = cv2.Sobel(src, ddepth, dx=0, dy=1, dst, ksize=-1, scale, delta, borderType)
```

#### Laplacian检测算子

由于 Laplacian使用了图像梯度，它内部的代码其实是调用了 Sobel 算子的。

```python
# src 传入的图像
# ddepth 图像深度
# ksize Sobel算子大小（卷积核大小），必须为技术，默认3
# scale 缩放导数的比例常数
# borderType 图像的边界，默认cv2.BORDER_DEFAULT
laplacian_img = cv2.Laplacian(src, ddepth, dst, ksize, scale, delta, borderType)
```

#### canny边缘检测算法

Canny 的目标是找到一个最优的边缘检测算法，让我们看一下最优边缘检测的三个主要评价标准:

1. **低错误率**: 标识出尽可能多的实际边缘，同时尽可能的减少噪声产生的误报。
2. **高定位性**: 标识出的边缘要与图像中的实际边缘尽可能接近。
3. **最小响应**: 图像中的边缘只能标识一次，并且可能存在的图像噪声不应标识为边缘。

```python
# image 灰度图
# threshold1 minval
# threshold2 maxval
canny_img = cv2.Canny(image, threshold1, threshold2)
```

### 模板匹配和霍夫变换

#### 模板匹配

```python
# image 灰度图
# templ 模板
# method 方法
# cv2.TM_SQDIFF 平方差匹配：利用模板于图像之间的平方差匹配，最好的匹配是0，匹配越差，值越大
# cv2.TM_CCORR 相关匹配：利用模板于图像之间的乘法匹配，值越大，匹配越高
# cv2.TM_CCOEFF 相关系数匹配：利用模板于图像之间的相关系数匹配，1是完美匹配，-1是最差匹配
res = cv2.matchTemplate(image, templ, method)
```

完成匹配后，使用cv2.minMaxLoc()方法查找最大值所在的位置。如果使用平方差匹配，则为最小值

```python
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)
```

#### 霍夫变换

用来提取图像中的直线和圆等几何形状

```python
import numpy as np
import cv2
import matplotlib.pyplot as plt

# 读取图像
img = cv2.imread('val2017/val2017/000000000872.jpg', 0)

edges = cv2.Canny(img, 50, 150)

lines = cv2.HoughLines(edges, 0.8, np.pi/180, 150)
for line in lines:
    rho, theta = line[0]
    a = np.cos(theta)
    b = np.sin(theta)
    x = rho*a
    y = rho*b
    x1 = int(x+1000*(-b))
    y1 = int(y+1000*a)
    x2 = int(x-1000*(-b))
    y2 = int(y-1000*a)
    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255))

plt.imshow(img[:, :, ::-1])
plt.show()
```

## 角点特征

### Harris算法和Shi-Tomas算法

1. Harris算法
   
   ```python
   import numpy as np
   import cv2
   import matplotlib.pyplot as plt
   
   # 读取图像
   img = cv2.imread('val2017/val2017/000000000872.jpg')
   gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
   
   # 角点检测
   gray = np.float32(gray)
   # 最后一个参数在0.04到0.05之间
   dst = cv2.cornerHarris(gray, 2, 3, 0.04)
   # 设置阈值，绘制角点
   img[dst > 0.001 * dst.max()] = [0, 0, 255]
   
   # 图像显示
   plt.figure(figsize=(10, 8), dpi=100)
   plt.imshow(img[:, :, ::-1])
   plt.title("角点检测")
   plt.xticks([])
   plt.yticks([])
   plt.show()
   ```

2. Shi-Tomas算法
   
   ```python
   import numpy as np
   import cv2
   import matplotlib.pyplot as plt
   
   # 读取图像
   img = cv2.imread('val2017/val2017/000000000872.jpg')
   gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
   
   # 角点检测
   # 最后一个参数在0.04到0.05之间
   corners = cv2.goodFeaturesToTrack(gray, 1000, 0.01, 10)
   # 设置阈值，绘制角点
   for i in corners:
       x, y = i.ravel()
       cv2.circle(img, (x, y), 2, (0, 0, 255), -1)
   
   # 图像显示
   plt.figure(figsize=(10, 8), dpi=100)
   plt.imshow(img[:, :, ::-1])
   plt.title("角点检测")
   plt.xticks([])
   plt.yticks([])
   plt.show()
   ```

### SIFT/SURF算法*

### Fast/ORB算法*

### LBP/HOG算法*

## 视频操作

### 视频读写

```python
import cv2

filepath = ""

# 读取视频对象
cap = cv2.VideoCapture(filepath)

# 获得视频信息
retval = cap.get(propId)

# 修改视频信息
cap_update = cap.set(propId, value)

# 判断图像是否读取成功
cap_success = cap.isOpened()

# 获取视频某一帧图像
ret, frame = cap.read()

# 显示图像
cv2.imshow()
# 持续时间，通常25ms
cv2.waitKey()

cap.release()
cv2.destroyWindow()
```

完整流程：

```python
import cv2

filepath = ""

cap = cv2.VideoCapture(filepath)

while cap.isOpened():
    ret, frame = cap.read()
    if ret:
        cv2.imshow('frame', frame)
        if cv2.waitKey(25) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyWindow()
```

**VideoCapture.get()参数**

| param | define                               |
| ----- | ------------------------------------ |
| 0     | 视频文件的当前位置（播放）以毫秒为单位                  |
| 1     | 基于以0开始的被捕获或解码的帧索引                    |
| 2     | 视频文件的相对位置（播放）：0=电影开始，1=影片的结尾。        |
| 3     | 在视频流的帧的宽度                            |
| 4     | 在视频流的帧的高度                            |
| 5     | 帧速率                                  |
| 6     | 编解码的4字-字符代码                          |
| 7     | 视频文件中的帧数                             |
| 8     | 返回对象的格式                              |
| 9     | 返回后端特定的值，该值指示当前捕获模式                  |
| 10    | 图像的亮度(仅适用于照相机)                       |
| 11    | 图像的对比度(仅适用于照相机)                      |
| 12    | 图像的饱和度(仅适用于照相机)                      |
| 13    | 色调图像(仅适用于照相机)                        |
| 14    | 图像增益(仅适用于照相机)（Gain在摄影中表示白平衡提升）       |
| 15    | 曝光(仅适用于照相机)                          |
| 16    | 指示是否应将图像转换为RGB布尔标志                   |
| 17    | × 暂时不支持                              |
| 18    | 立体摄像机的矫正标注（目前只有DC1394 v.2.x后端支持这个功能） |

## 保存视频

```python
import cv2

filepath = ""

cap = cv2.VideoCapture(filepath)

# 获取图像的属性
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))

# 创建写入对象
# 视频编解器
# Wins：DIVX(.avi)
# OS: MJPG(.mp4)、DIVX(.avi)、X264(.kmv)
fourcc = cv2.VideoWriter_fourcc('D', 'I', 'V', 'X')
# filename 保存位置
# fourcc 指定视频编解器的4字节代码
# fps 帧率
# frameSize 帧大小
out = cv2.VideoWriter(filename, fourcc, fps, (frame_width, frame_height))

while True:
    ret, frame = cap.read()
    # 将画面翻转
    frame = cv.flip(frame, 0)
    if ret:
        out.write(frame)
    else:
        break

cap.release()
out.release()
cv2.destroyWindow()
```

### 视频追踪

#### meanshift

```python
# probImage ROI区域，目标的直方图的反向投影
# window 初始搜索窗口
# criteria 确定窗口搜索停止的准则：迭代次数达到设置的最大值，窗口中心的漂移值大于某个阈值
cv2.meanShift(probImage, window, criteria)
```

```python
import cv2
import numpy as np

filepath = ""

cap = cv2.VideoCapture(filepath)

# 获取第一帧图像
ret, frame = cap.read()
# 目标位置（行、高、列、宽）
r, h, c, w = 197, 141, 0, 208
track_window = (c, r, w, h)
# 指定目标区域
roi = frame[r:r + h, c:c + w]

# 计算直方图
# 转换色彩空间
hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
# 去除低亮度的值
mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))
# 计算直方图
roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])
# 归一化
cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)

# 目标追踪
# 设置窗口搜索终止条件，最大迭代次数，窗口中心飘逸最小值
term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

while True:
    # 获取每一帧图像
    ret, frame = cap.read()
    if ret:
        # 计算直方图的反向投影
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)

        # 进行meanshift追踪
        ret, track_window = cv2.meanShift(dst, track_window, term_crit)

        # 将追踪的位置绘制在视频上
        x, y, w, h = track_window
        img2 = cv2.rectangle(frame, (x, y), (x + w, y + h), 255, 2)
        cv2.imshow('frame', img2)

        if cv2.waitKey(60) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyWindow('frame')
```

#### Camshift

```python
import cv2
import numpy as np

filepath = ""

cap = cv2.VideoCapture(filepath)

# 获取第一帧图像
ret, frame = cap.read()
# 目标位置（行、高、列、宽）
r, h, c, w = 197, 141, 0, 208
track_window = (c, r, w, h)
# 指定目标区域
roi = frame[r:r + h, c:c + w]

# 计算直方图
# 转换色彩空间
hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
# 去除低亮度的值
mask = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))
# 计算直方图
roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])
# 归一化
cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)

# 目标追踪
# 设置窗口搜索终止条件，最大迭代次数，窗口中心飘逸最小值
term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

while True:
    # 获取每一帧图像
    ret, frame = cap.read()
    if ret:
        # 计算直方图的反向投影
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)

        # 进行meanshift追踪
        ret, track_window = cv2.CamShift(dst, track_window, term_crit)

        # 将追踪的位置绘制在视频上
        pts = cv2.boxPoints(ret)
        pts = np.int0(pts)
        img2 = cv2.polylines(frame, [pts], 255, 2)
        cv2.imshow('frame', img2)

        if cv2.waitKey(60) & 0xFF == ord('q'):
            break

cap.release()
cv2.destroyWindow('frame')
```
