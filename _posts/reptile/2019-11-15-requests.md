---
layout: post
title: 使用 requests
subtitle: 
author: Balbo Cheng
categories: programming-language
tags: [python, reptile]
sidebar: []
---

## 基本用法

### 实例引入

```python
import requests

r = requests.get('http://baidu.com/')
print(type(r))
print(r.status_code)
print(type(r.text))
print(r.text)
print(r.cookies)
```

运行结果：

```
<class 'requests.models.Response'>
200
<class 'str'>
<html>
<meta http-equiv="refresh" content="0;url=http://www.baidu.com/">
</html>
<RequestsCookieJar[]>
```

### GET 请求

```python
import requests

r = requests.get('http://httpbin.org/get')
print(r.text)
```

运行结果：

```
{
  "args": {}, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.22.0"
  }, 
  "origin": "113.100.6.27, 113.100.6.27", 
  "url": "https://httpbin.org/get"
}
```

附加额外请求:

```python
import requests

data = {
    'name': 'germey',
    'age': 22,
}
r = requests.get('http://httpbin.org/get', params=data)
print(r.text)
```

### 抓取二进制数据

```python
import requests

r = requests.get('http://github.com/favicon.ico')
with open('e://favicon.ico', 'wb') as f:
    f.write(r.content)
```

### 添加 headers

```python
import requests

headers = {'User-Agent': 'Mozilla/5.0 ' \
                         '(Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 ' \
                         '(KHTML, like Gecko) Version/5.1 Safari/534.50'}
response = requests.get('http://www.baidu.com', headers=headers)
print(response.text)
```

## 高级用法

### 上传文件

```python
import requests

files = {'file': open('favicon.ico', 'rb')}
r = requests.post('http://httpbin.org/post', files=files)
print(r.text)
```

运行结果：

```
{
  "args": {}, 
  "data": "", 
  "files": {
    "file": "data:application/octet-stream;base64,AAA ... A="
  }, 
  "form": {}, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "6665", 
    "Content-Type": "multipart/form-data; boundary=a07be83274db9e46b0713544033f2f6f", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.22.0"
  }, 
  "json": null, 
  "origin": "113.100.6.27, 113.100.6.27", 
  "url": "https://httpbin.org/post"
}
```

### Cookies

```python
# 获取cookie
import requests

response = requests.get('http://www.baidu.com')
print(response.cookies)
print(type(response.cookies))
for k, v in response.cookies.items():
    print(k+':'+v)
```

运行结果：

```
<RequestsCookieJar[<Cookie BDORZ=27315 for .baidu.com/>]>
<class 'requests.cookies.RequestsCookieJar'>
BDORZ:27315
```

### 会话维持

```python
import requests

session = requests.Session()
session.get('http://httpbin.org/cookies/set/number/12345')
response = session.get('http://httpbin.org/cookies')
print(response.text)
```

运行结果：

```
{
  "cookies": {
    "number": "12345"
  }
}
```

### SSL证书验证

```python
import requests
from requests.packages import urllib3

urllib3.disable_warnings()  #从urllib3中消除警告
response = requests.get('https://www.12306.cn',verify=False)  #证书验证设为FALSE
print(response.status_code)
```

### 代理设置

对于某些网站，在测试的时候请求几次，能正常获取内容。但是一旦开始大规模爬取，对于大规模且频繁的请求，网站可能会弹出验证码，或者跳转到登陆验证界面，甚至会直接封禁客户端的 IP，导致一定时间段内无法访问。

```python
import requests

proxies = {
    'http': 'http://user:password@10.10.1.10:3128',
    'https': 'http://user:password@10.10.1.10:1080',
}

requests.get('http://www.taobao.com', proxies=proxies)
```

### 超时设置

```python
import requests
from requests.exceptions import ReadTimeout

try:
    res = requests.get('http://taobao.com', timeout=1)
    print(res.status_code)
except ReadTimeout as timeout:
    print(timeout)
```